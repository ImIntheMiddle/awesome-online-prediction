# ğŸ˜ Awesome-Online-Prediction [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A curated list of awesome online-prediction papers, tools, and resources.

Created and hosted by the members of group 5 in the 28th **M**eeting on **I**mage **R**ecognition and **U**nderstanding ([MIRU2025](https://cvim.ipsj.or.jp/MIRU2025/index-en.html)) Wakate program.

[ç”»åƒã®èªè­˜ãƒ»ç†è§£ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ ï¼ˆMIRU2025ï¼‰](https://cvim.ipsj.or.jp/MIRU2025/index.html)ã§ä¼ç”»ã•ã‚ŒãŸ [è‹¥æ‰‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ](https://sites.google.com/view/miru2025wakate) ã«ãŠã‘ã‚‹ï¼Œã‚°ãƒ«ãƒ¼ãƒ—ï¼•ã«ã‚ˆã‚‹å–ã‚Šçµ„ã¿ã®æˆæœã§ã™ï¼

ã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬ã«é–¢ã™ã‚‹é‡è¦ãªè«–æ–‡ï¼Œãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼Œå­¦ç¿’ã®ãŸã‚ã®ãƒªã‚½ãƒ¼ã‚¹ãªã©ã‚’ã¾ã¨ã‚ã¦ã„ã¾ã™ï¼

> [!TIP]
> Super-awesome ones are marked with a starğŸŒŸ.
> 
> Japanese-only references are marked with JapanğŸ—¾.
> 
> ç‰¹ã«é‡è¦ãƒ»æœ‰ç”¨ã¨æ€ã‚ã‚Œã‚‹ã‚‚ã®ã«ã¯æ˜Ÿå°ğŸŒŸã‚’ä»˜ã—ã¦ã„ã¾ã™ï¼
> 
> æ—¥æœ¬èªã®ã¿ã®æ–‡çŒ®ã«ã¯æ—¥æœ¬ğŸ—¾ã‚’ä»˜ã—ã¦ã„ã¾ã™ï¼

Status: ![](https://geps.dev/progress/55)

# ğŸ“‘ Papersï¼ˆè«–æ–‡ï¼‰
## Awesome-Surveysï¼ˆã‚µãƒ¼ãƒ™ã‚¤ï¼‰
### 1. ğŸŒŸ[Hoi _et al._(2018), Online Learning: A Comprehensive Survey](https://arxiv.org/abs/1802.02871)
  - Published in 2018, this survey has been cited over 1,000 times and broadly covers online learning and online prediction topics.
  - 2018å¹´ã®ç™ºè¡¨ã ãŒï¼Œ1000å›ä»¥ä¸Šå¼•ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚µãƒ¼ãƒ™ã‚¤ï¼ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã‚„ã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬ã®å†…å®¹ã‚’åºƒãå–ã‚Šä¸Šã’ã¦ã„ã‚‹ï¼
### 2. ğŸŒŸ[Foster and Rakhlin (2023), Foundations of Reinforcement Learning and Interactive Decision Making](https://arxiv.org/abs/2312.16730)
  - This lecture note introduces various decision-making problems, including online learning and prediction, and explains the theoretical foundations of online reinforcement learning.
  - ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ãƒ»äºˆæ¸¬ã‚’å«ã‚ãŸå„ç¨®ã®æ„æ€æ±ºå®šå•é¡Œã«ã¤ã„ã¦ç´¹ä»‹ã—ï¼Œã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¼·åŒ–å­¦ç¿’ã®ç†è«–çš„åŸºç¤ã¾ã§ã‚’è§£èª¬ã—ãŸè¬›ç¾©ãƒãƒ¼ãƒˆï¼
### 3. ğŸŒŸ[Shalev-Shwartz (Foundations and Trends in Machine Learning, 2011), Online Learning and Online Convex Optimization](https://www.cs.huji.ac.il/~shais/papers/OLsurvey.pdf)
  - This survey provides a comprehensive overview of online learning and online convex optimization.
  - ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã¨ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å‡¸æœ€é©åŒ–ã«é–¢ã™ã‚‹åŒ…æ‹¬çš„ãªã‚µãƒ¼ãƒ™ã‚¤è«–æ–‡ï¼
### 4. [Orabona (2019), A Modern Introduction to Online Learning](https://arxiv.org/abs/1912.13213)
  - Awesome paper that introduces the basic concepts of online learning through a modern view of online convex optimization, covering everything from fundamental concepts to dynamic regret.
  - ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å‡¸æœ€é©åŒ–ã®ç¾ä»£çš„è¦–ç‚¹ã‹ã‚‰ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã®åŸºæœ¬æ¦‚å¿µã‚’ç´¹ä»‹ã—ï¼ŒåŸºæœ¬æ¦‚å¿µã‹ã‚‰å‹•çš„ãƒªã‚°ãƒ¬ãƒƒãƒˆã¾ã§ã‚’åºƒãæ‰±ã£ã¦ã„ã‚‹ï¼

## Awesome-Theoretical Researchï¼ˆåŸºç¤ç ”ç©¶ï¼‰
### 5. [Hannan (Contributions to the Theory of Games, 1957), Approximation to Bayes risk in repeated plays](http://www-stat.wharton.upenn.edu/~steele/Resources/Projects/SequenceProject/Hannan.pdf)
  - a
  - a
### 6. [Nesterov (Soviet Mathematics Doklady, 1983), A Meyhod of Solving a Convex Programming Problem with Convergence Rate O(1/kÂ²)](https://hengshuaiyao.github.io/papers/nesterov83.pdf)
  - a
  - a
### 7. [Littlestone (Machine Learning, 1988), Learning Quickly When Irrelevant Attributes Abound: A New Linear-Threshold Algorithm](https://link.springer.com/article/10.1023/A:1022869011914)
  - a
  - a
### 8. [Herbster and Warmuth (Machine Learning, 1998), Tracking the Best Expert](https://link.springer.com/article/10.1023/A:1007424614876)
  - a
  - a
### 9. [Vovk (JCSS, 1998), A Game of Prediction with Expert Advice](https://www.sciencedirect.com/science/article/pii/S0022000097915567)
  - a
  - a
### 10. [Kivinen and Warmuth (EuroCOLT1999), Averaging Expert Predictions](https://link.springer.com/chapter/10.1007/3-540-49097-3_13)
  - a
  - a
### 11. [Kivinen and Warmuth (Machine Learning, 2001), Relative Loss Bounds for Multidimensional Regression Problems](https://link.springer.com/article/10.1023/A:1017938623079)
  - a
  - a
### 12. [Zinkevich (ICML2003), Online Convex Programming and Generalized Infinitesimal Gradient Ascent](https://people.eecs.berkeley.edu/~brecht/cs294docs/week1/03.Zinkevich.pdf)
  - a
  - a
### 13. [Kalai and Vempara (JCSS, 2005), Efficient algorithms for online decision problems](https://www.sciencedirect.com/science/article/pii/S0022000004001394) 
  - a
  - a
### 14. [Crammer _et al._ (JMLR, 2006), Online Passive-Aggressive Algorithms](https://jmlr.org/papers/v7/crammer06a.html)
  - a
  - a
### 15. [Hazan _et al._ (Machine Learning, 2007), Logarithmic Regret Algorithms for Online Convex Optimization](https://link.springer.com/article/10.1007/s10994-007-5016-8)
  - a
  - a
### 16. [Cesa-Bianchi _et al._ (Machine Learning, 2007), Improved second-order bounds for prediction with expert advice](https://arxiv.org/abs/math/0602629)
  - a
  - a
### 17. [Crammer _et al._ (EMNLP2009), Multi-Class Confidence Weighted Algorithms](https://aclanthology.org/D09-1052/)
  - a
  - a
### 18. [Crammer _et al._ (NeurIPS2009), Adaptive Regularization of Weight Vectors](https://papers.nips.cc/paper_files/paper/2009/hash/8ebda540cbcc4d7336496819a46a1b68-Abstract.html)
  - a
  - a
### 19. [Duchi _et al._ (JMLR, 2010), Adaptive Subgradient Methods for Online Learning and Stochastic Optimization](https://jmlr.org/papers/v12/duchi11a.html)
  - a
  - a
### 20. [McDonald _et al._ (NAACL HLT2010), Distributed Training Strategies for the Structured Perceptron](https://aclanthology.org/N10-1069.pdf)
  - a
  - a
### 21. [Chu _et al._ (KDD2011), Unbiased online active learning in data streams](https://dl.acm.org/doi/10.1145/2020408.2020444)
  - a
  - a
### 22. [Shalev-Shwartz _et al._ (Mathematical Programming, 2017), Pegasos: primal estimated sub-gradient solver for SVM](https://link.springer.com/article/10.1007/s10107-010-0420-4)
  - a
  - a
### 23. [Cesa-Bianchi and Lugosi (JCSS, 2012), Combinatorial bandits](https://www.sciencedirect.com/science/article/pii/S0022000012000219)
  - a
  - a
### 24. [Suehiro _et al._ (ALT2012), Online Prediction under Submodular Constraints](https://api.lib.kyushu-u.ac.jp/opac_download_md/1932327/alt12.pdf)
  - a
  - a
### 25. [Arora _et al._ (Theory of Computing, 2012), The Multiplicative Weights Update Method: a Meta-Algorithm and Applications](https://theoryofcomputing.org/articles/v008a006/)
  - a
  - a
### 26. [Wang _et al._ (ICML2012), Exact Soft Confidence-Weighted Learning](https://arxiv.org/abs/1206.4612)
  - a
  - a
### 27. [Bubeck and Slivkins (COLT2012), The best of both worlds: stochastic and adversarial bandits](http://sbubeck.com/COLT12_BS.pdf)
  - a
  - a
### 28. [Neu and BartÃ³k (ALT2013), An efficient algorithm for learning with semi-bandit feedback](https://arxiv.org/abs/1305.2732)
  - a
  - a
### 29. [Ho _et al._(NeurIPS2013), More Effective Distributed ML via a Stale Synchronous Parallel Parameter Server](https://fid3024.github.io/papers/2013%20-%20More%20Effective%20Distributed%20ML%20via%20a%20Stale%20Sychronous%20Parallel%20Parameter%20Server.pdf)
  - a
  - a
### 30. [McMahan_ _et al.__(KDD2013), Ad Click Prediction: a View from the Trenches](https://research.google/pubs/ad-click-prediction-a-view-from-the-trenches/)
  - a
  - a
### 31. [Gaillard _et al._ (COLT2014), A Second-order Bound with Excess Losses](https://arxiv.org/abs/1402.2044)
  - a
  - a
### 32. [Kingma and Ba (ICLR2015), Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)
  - a
  - a
### 33. [Luo and Schapire (COLT2015), Achieving All with No Parameters: AdaNormalHedge](https://proceedings.mlr.press/v40/Luo15.pdf)
  - ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆçµ±åˆå•é¡Œã«ãŠã„ã¦ï¼Œäº‹å‰æƒ…å ±ï¼ˆã‚¹ãƒ†ãƒƒãƒ—ã‚µã‚¤ã‚ºã‚„ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®æ•°ãªã©ï¼‰ã‚’å¿…è¦ã¨ã—ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ãƒªãƒ¼ãªã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€ŒAdaNormalHedgeã€ã‚’ææ¡ˆï¼
### 34. [Hazan _et al._ (ICML2017), Efficient Regret Minimization in Non-Convex Games](https://proceedings.mlr.press/v70/hazan17a.html)
  - éå‡¸ãªæå¤±é–¢æ•°ã‚’å¯¾è±¡ã¨ã—ãŸã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç ”ç©¶
  - æ™‚é–“å¹³æ»‘åŒ–ã—ãŸæå¤±ï¼ˆéå»kå›ã®æå¤±ã‚’å¹³å‡ã—ãŸã‚‚ã®ï¼‰ã‹ã‚‰è¨ˆç®—ã•ã‚Œã‚‹å°„å½±å‹¾é…ã®å¤§ãã•ã‚’åŸºã«ã—ãŸæ–°ã—ã„å°ºåº¦ã€Œå±€æ‰€ãƒªã‚°ãƒ¬ãƒƒãƒˆã€ã‚’å®šç¾©ã—ã€ãã‚Œã‚’åŠ¹ç‡çš„ã«æœ€å°åŒ–ã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆ
### 35. [Zhang _et al._ (NeurIPS2018), Adaptive Online Learning in Dynamic Environments](https://arxiv.org/abs/1810.10815)
  - ä»»æ„ã®æ¯”è¼ƒå¯¾è±¡ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¯¾ã™ã‚‹å‹•çš„ãƒªã‚°ãƒ¬ãƒƒãƒˆã®ç†è«–çš„ãªä¸‹é™ã‚’åˆã‚ã¦æç¤ºã—ãŸç ”ç©¶
  - ç†è«–çš„ãªä¸‹é™ã¨ä¸€èˆ¬çš„ãªOGDã¨ã®å‹•çš„ãƒªã‚°ãƒ¬ãƒƒãƒˆã«ä¹–é›¢ãŒã‚ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã—ï¼Œãã®è§£æ±ºç­–ã¨ã—ã¦ç•°ãªã‚‹ã‚¹ãƒ†ãƒƒãƒ—ã‚µã‚¤ã‚ºã‚’æŒã¤è¤‡æ•°ã®OGDï¼ˆã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆï¼‰ã‚’ãƒ¡ã‚¿ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§é©å¿œçš„ã«çµ±åˆã™ã‚‹æ‰‹æ³•ã€ŒAderã€ã‚’ææ¡ˆ
### 36. [Finn _et al._ (ICLR2019), Online Meta-Learning](https://arxiv.org/abs/1902.08438)
  - a
  - a
### 37. [Zhao _et al._ (NeurIPS2020), Dynamic Regret of Convex and Smooth Functions](https://arxiv.org/abs/2007.03479)
  - a
  - a
### 38. [Ito (NeurIPS2021), On Optimal Robustness to Adversarial Corruption in Online Decision Problems](https://arxiv.org/abs/2109.10963)
  - a
  - a
### 39. [Zimmert and Seldin (JMLR, 2021), Tsallis-INF: An Optimal Algorithm for Stochastic and Adversarial Bandits](https://arxiv.org/abs/1807.07623)
  - a
  - a
### 40. [Baby _et al._ (NeurIPS2023), Online Label Shift: Optimal Dynamic Regret meets Practical Algorithms](https://neurips.cc/virtual/2023/poster/71994)
  - a
  - a
### 41. [Dai _et al._ (CVPR2025), Label Shift Meets Online Learning: Ensuring Consistent Adaptation with Universal Dynamic Regret](https://openaccess.thecvf.com/content/CVPR2025/html/Dai_Label_Shift_Meets_Online_Learning_Ensuring_Consistent_Adaptation_with_Universal_CVPR_2025_paper.html)
  - a
  - a

## Awesome-Applied Researchï¼ˆå¿œç”¨ç ”ç©¶ï¼‰
### 42. ğŸŒŸ[Bashratat _et al._ (CVPR2008), Learning object motion patterns for anomaly detection and improved object detection](https://ieeexplore.ieee.org/document/4587510)
  - Awesome paper that learns object motion patterns in surveillance videos for anomaly detection and improved object detection.
  - ç›£è¦–æ˜ åƒã«ãŠã‘ã‚‹å¿œç”¨ã¨ã—ã¦ï¼Œç‰©ä½“ã®å‹•ããƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã—ï¼Œç•°å¸¸æ¤œçŸ¥ã¨ç‰©ä½“æ¤œå‡ºã‚’æ”¹å–„ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ãŸè«–æ–‡ï¼
### 43. [Grnarova _et al._ (ICLR2018), An Online Learning Approach to Generative Adversarial Networks](https://arxiv.org/abs/1706.03269)
  - Awesome paper that applies online learning techniques to GAN training for improved stability.
  - GANã®è¨“ç·´ã«ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’æ‰‹æ³•ã‚’é©ç”¨ã—ã¦å®‰å®šæ€§ã‚’å‘ä¸Šã•ã›ãŸè«–æ–‡ï¼
### 44. [Song _et al._ (Machine Learning, 2024), No Regret Sample Selection with Noisy Labels](https://arxiv.org/abs/2003.03179)
  - Awesome paper that proposes adaptive k-set selection for training DNNs with noisy labels while providing theoretical regret bounds. 
  - ãƒã‚¤ã‚¸ãƒ¼ãƒ©ãƒ™ãƒ«ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ã§ã®DNNè¨“ç·´ã«ãŠã„ã¦ï¼Œç†è«–çš„ãªregretä¿è¨¼ã‚’æŒã¤é©å¿œçš„k-seté¸æŠæ‰‹æ³•ã‚’ææ¡ˆã—ãŸè«–æ–‡ï¼
### 45. [Song _et al._ (WACV2020), Adaptive Aggregation of Arbitrary Online Trackers with a Regret Bound](https://openaccess.thecvf.com/content_WACV_2020/papers/Song_Adaptive_Aggregation_of_Arbitrary_Online_Trackers_with_a_Regret_Bound_WACV_2020_paper.pdf)
  - a
  - a
### 46. [Matsuo _et al._ (ICASSP2023), Learning from Label Proportion with Online Pseudo-Label Decision by Regret Minimization](https://arxiv.org/abs/2302.08947)
  - a
  - a
### 47. [Å vihrovÃ¡ _et al._ (2025), *Designing digital health interventions with causal inference and multi-armed bandits: a review*](https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2025.1435917/full)
  - ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢åˆ†é‡ã«ãŠã‘ã‚‹ Just-In-Time Interventiobn ã«å¤šè…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œã¨å› æœè§£æã‚’å°å…¥ã™ã‚‹æ–¹æ³•è«–ã«é–¢ã™ã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼è«–æ–‡ã€‚
  - è¢«é¨“è€…ã®å¥åº·çŠ¶æ…‹ã‚’é€æ¬¡çš„ã«ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã—ã€é©åˆ‡ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§"ä»‹å…¥"ã—ã¦è¡Œå‹•å¤‰å®¹ã‚’ä¿ƒã™æ çµ„ã¿ã€‚
### 48. [Kumar _et al._ (AAAI2024), Using adaptive bandit experiments to increase and investigate engagement in mental health](https://ojs.aaai.org/index.php/AAAI/article/view/30328)
  - ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹ã«ãŠã‘ã‚‹å€‹åˆ¥åŒ–åŒ»ç™‚ã«ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œã‚’é©ç”¨ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ãŸã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è«–æ–‡ï¼
### 49. [GutiÃ©rrez _et al._ (2017), A Multi-armed Bandit to Smartly Select a Training Set from Big Medical Data](https://link.springer.com/chapter/10.1007/978-3-319-66179-7_5)
  - å¤§è¦æ¨¡ãªåŒ»ç™‚ç”»åƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é©åˆ‡ã‹ã¤åŠ¹ç‡çš„ã«é¸æŠã™ã‚‹å•é¡Œã‚’å¤šè…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œã¨ã—ã¦å®šå¼åŒ–ã—ãŸã€‚
  - è„³ç”»åƒã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹ç‰¹å¾´é‡ã‹ã‚‰å¹´é½¢ã‚’äºˆæ¸¬ã™ã‚‹å•é¡Œã«ãŠã„ã¦ã€äº‹å‰ã«è¦³æ¸¬ã§ãã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ‰ç”¨ãªã‚µãƒ³ãƒ—ãƒ«ã‚’é¸æŠã™ã‚‹ã¨ã„ã†å•é¡Œã«è½ã¨ã—è¾¼ã‚“ã ã€‚
  - ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ã€æœ‰ç›Šãã†ãªã‚¯ãƒ©ã‚¹ã‚¿ã‚’æ´»ç”¨ã—ã¤ã¤ã€ä»–ã®ã‚¯ãƒ©ã‚¹ã‚¿ã‚‚æ¢ç´¢ã—ã¦ã„ãã€ã¨ã„ã†ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ã¨ã£ãŸã€‚
  - æ‰‹æ³•ã¯ç·šå½¢å›å¸°ãƒ™ãƒ¼ã‚¹ã§æ·±å±¤å­¦ç¿’ã§ã¯ãªã„
### 50. [Zheng and Kwok (2017), Follow the Moving Leader in Deep Learning](https://proceedings.mlr.press/v70/zheng17a.html)
  - **è°·å£èª¿æŸ»ä¸­**
  - a
  - a
### 51. [Pandian _et al._ (Scientific Reports, 2025), Enhancing lane detection in autonomous vehicles with multi-armed bandit ensemble learning](https://www.nature.com/articles/s41598-025-86743-z)
  - a
  - a

# ğŸ§° Toolsï¼ˆãƒ„ãƒ¼ãƒ«ï¼‰
## Awesome-Librariesï¼ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼‰
### 52. ğŸŒŸ[River](https://github.com/online-ml/river)
  - A Python library for online machine learning (with over 5k stars), covering time series forecasting, bandits, and so on.
  - ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ©Ÿæ¢°å­¦ç¿’ã®ãŸã‚ã®Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆ5000ã‚¹ã‚¿ãƒ¼è¶…ãˆï¼‰ã§ã€æ™‚ç³»åˆ—äºˆæ¸¬ã‚„ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆãªã©ã‚’ã‚«ãƒãƒ¼ã—ã¦ã„ã‚‹ã€‚
### 53. [scikit-multiflow](https://scikit-multiflow.readthedocs.io/en/stable/index.html)
  - A machine learning library for streaming data in Python (~0.8k stars). Although it can handle drift detection and has a variety of algorithms other than neural networks, River is more common nowadays.
  - ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã«é©ã—ãŸPythonå®Ÿè£…ã®æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆç´„800ã‚¹ã‚¿ãƒ¼ï¼‰ï¼ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºæ©Ÿèƒ½ã‚’å‚™ãˆï¼Œãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä»¥å¤–ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚‚è±Šå¯Œã ãŒï¼Œç¾åœ¨ã§ã¯Riverã«ä¸»æµãŒç§»ã£ãŸï¼
### 54. ğŸŒŸ[Vowpal Wabbit](https://vowpalwabbit.org/index.html)
  - A machine learning library implemented in various languages (with over 8,500 stars), primarily developed by Microsoft. It supports various learning paradigms, including online learning, and can handle online prediction-related stuff like contextual bandits."
  - MicrosoftãŒä¸­å¿ƒã¨ãªã£ã¦é–‹ç™ºã—ã¦ã„ã‚‹å¤šè¨€èªå®Ÿè£…ã®æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆ8500ã‚¹ã‚¿ãƒ¼è¶…ãˆï¼‰ï¼ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã‚’å«ã‚€å¤šæ§˜ãªå­¦ç¿’æ§˜å¼ã«å¯¾å¿œã—ã¦ãŠã‚Šï¼ŒContextual banditsç­‰ã‚’æ‰±ãˆã‚‹ï¼
### 55. [MOA](https://moa.cms.waikato.ac.nz/)
  - An open-source Java framework designed for sequential data processing, boasting over 600 stars.
  - JAVAã§å®Ÿè£…ã•ã‚ŒãŸï¼Œé€æ¬¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ç”¨ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼600ã‚¹ã‚¿ãƒ¼è¶…ãˆï¼ 
### 56. [CapyMOA](https://capymoa.org/)
  - Python implementation of MOA, significantly faster than River and suited for real-time processing.
  - MOAã®Pythonç‰ˆï¼Riverã‚ˆã‚Šã‚‚å¤§å¹…ã«é«˜é€ŸåŒ–ã•ã‚Œã¦ãŠã‚Šï¼Œãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†å‘ãï¼
### 57. [Jubatas](http://jubat.us/ja/index.html)
  - A distributed processing framework for online machine learning, jointly developed by PFN and NTT.
  - PFNã¨NTTãŒå…±åŒã§é–‹ç™ºã—ã¦ã„ãŸã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ©Ÿæ¢°å­¦ç¿’å‘ã‘ã®åˆ†æ•£å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼
### 58. [Deep-River](https://online-ml.github.io/deep-river/)
  - A library suitable for online learning of deep learning models implemented in PyTorch. Same developers as River (online-ml)."
  - PyTorchã§å®Ÿè£…ã•ã‚ŒãŸæ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã«é©ã—ãŸãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼Riverã¨åŒã˜online-mlãŒé–‹ç™ºï¼

## Awesome-Probability Inequalities (ç¢ºç‡ä¸ç­‰å¼)
### 59. [Probability inequalities](https://probability.oer.math.uconn.edu/wp-content/uploads/sites/2187/2020/08/ch15M.pdf)
  - Introduction of several probability inequalities used in proofs.
  - è¨¼æ˜ã«ä½¿ç”¨ã•ã‚Œã‚‹ç¢ºç‡ä¸ç­‰å¼ãŒã„ãã¤ã‹ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹ï¼
### 60. ğŸŒŸ[Markov's Inequality ... Made Easy!](https://www.youtube.com/watch?v=e-nAr3MkAII)
  - Awesome YouTube video on Markov's inequality.
  - ãƒãƒ«ã‚³ãƒ•ã®ä¸ç­‰å¼ã«ã¤ã„ã¦è§£èª¬ã—ãŸYouTubeå‹•ç”»ï¼
### 61. ğŸŒŸ[Chebyshev's Inequality ... Made Easy!](https://www.youtube.com/watch?v=mlelI1LA9o4)
  - Awesome YouTube video on Chebyshev's inequality.
  - ãƒã‚§ãƒ“ã‚·ã‚§ãƒ•ã®ä¸ç­‰å¼ã«ã¤ã„ã¦è§£èª¬ã—ãŸYouTubeå‹•ç”»ï¼
### 62. ğŸ—¾[ã€å¤§å­¦æ•°å­¦ã€‘ãƒã‚§ãƒ“ã‚·ã‚§ãƒ•ã®ä¸ç­‰å¼ã€ç¢ºç‡çµ±è¨ˆã€‘](https://www.youtube.com/watch?v=d-ugoDdXWrU)
  - ãƒ¨ãƒ“ãƒãƒªã«ã‚ˆã‚‹ãƒã‚§ãƒ“ã‚·ã‚§ãƒ•ã®ä¸ç­‰å¼ã«ã¤ã„ã¦ã®è§£èª¬å‹•ç”»ï¼
### 63. [What is the Chernoff Bound?](https://www.youtube.com/watch?v=WKUeBoQp2Uo)
  - Awesome YouTube video on Chernoff bound.
  - ãƒã‚§ãƒ«ãƒãƒ•é™ç•Œã«ã¤ã„ã¦è§£èª¬ã—ãŸYouTubeå‹•ç”»ï¼
### 64. [L 27 | Cauchy Schwarz Inequality | Probability & Statistics | Digital Communication](https://www.youtube.com/watch?v=14-JD5KiUz0)
  - Awesome YouTube video on Cauchy-Schwarz inequality.
  - ã‚³ãƒ¼ã‚·ãƒ¼ï¼ã‚·ãƒ¥ãƒ¯ãƒ«ãƒ„ã®ä¸ç­‰å¼ã«ã¤ã„ã¦è§£èª¬ã—ãŸYouTubeå‹•ç”»ï¼
  - ãƒã‚§ãƒ«ãƒãƒ•é™ç•Œã«ã¤ã„ã¦è§£èª¬ã—ãŸYouTubeå‹•ç”»ï¼
### 65. [Jensen's Inequality](https://www.youtube.com/watch?v=u0_X2hX6DWE)
  - Awesome YouTube video on Jensen's inequality.
  - ã‚¤ã‚§ãƒ³ã‚»ãƒ³ã®ä¸ç­‰å¼ã«ã¤ã„ã¦è§£èª¬ã—ãŸYouTubeå‹•ç”»ï¼
### 66. [A Visual Introduction to Hoeffding's Inequality - Statistical Learning Theory](https://www.youtube.com/watch?v=lsYPC0MuLJA)
  - Awesome YouTube video visualizing the concept of Hoeffding's inequality.
  - ã¸ãƒ•ãƒ‡ã‚£ãƒ³ã‚°ã®ä¸ç­‰å¼ã«ã¤ã„ã¦è¦–è¦šçš„ã«è§£èª¬ã—ãŸYouTubeå‹•ç”»ï¼
### 67. [Supplemental Lecture notes Hoeffdingâ€™s inequality](https://cs229.stanford.edu/extra-notes/hoeffding.pdf)
  - Lecture material of Stanford University, including an explanation of moment generating functions and a proof of Hoeffding's inequality.
  - ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆæ¯é–¢æ•°ã®è§£èª¬ã‚„Hoeffdingã®ä¸ç­‰å¼ã®è¨¼æ˜ã‚’å«ã‚“ã ï¼Œã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§å­¦ã®è¬›ç¾©è³‡æ–™ï¼
### 68. ğŸ—¾[ãƒ˜ãƒ•ãƒ‡ã‚£ãƒ³ã‚°ã®ä¸ç­‰å¼(Hoeffding's inequality)ã¨è«¸ã€…ã®ç¢ºç‡ã®è©•ä¾¡ã®ä¸ç­‰å¼](https://ludu-vorton.hatenablog.com/entry/2019/06/06/073000)
  - çµ±è¨ˆçš„å­¦ç¿’ç†è«–ã§ç¢ºç‡ã®è©•ä¾¡ã§ç”¨ã„ã‚‰ã‚Œã‚‹æ§˜ã€…ãªä¸ç­‰å¼ï¼ˆã¸ãƒ•ãƒ‡ã‚£ãƒ³ã‚°ã®ä¸ç­‰å¼ã‚’å«ã‚€ï¼‰ã«ã¤ã„ã¦ã®è§£èª¬ï¼

## Awesome-Convex Optimization (å‡¸æœ€é©åŒ–)
### 69. [Subgradients/Subderivatives - Convex Analysis](https://www.youtube.com/watch?v=o0rOaN5uo64)
  - Awesome YouTube video on subgradients and subderivatives.
  - åŠ£å‹¾é…/åŠ£å¾®åˆ†ã«ã¤ã„ã¦è§£èª¬ã—ãŸYouTubeå‹•ç”»ï¼
### 70. [Lipschitz Continuity | Lipschitz Condition](https://www.youtube.com/watch?v=P-OFTp3BPis) 
  - Awesome YouTube video on Lipschitz continuity.
  - ãƒªãƒ—ã‚·ãƒƒãƒ„é€£ç¶šã«ã¤ã„ã¦è§£èª¬ã—ãŸYouTubeå‹•ç”»ï¼
### 71. ğŸ—¾[ãƒªãƒ—ã‚·ãƒƒãƒ„é€£ç¶šã¨ã¯ï½å®šç¾©ã¨æ€§è³ªãƒ»ä»–ã®é€£ç¶šæ€§ã¨ã®é–¢ä¿‚ãªã©ï½](https://mathlandscape.com/lipschitz/)
  - ãƒªãƒ—ã‚·ãƒƒãƒ„é€£ç¶šã®å®šç¾©ã‚„ä¾‹ï¼Œæ€§è³ªï¼Œãã®ä»–ã®é€£ç¶šæ€§ã¨ã®é–¢é€£æ€§ã«ã¤ã„ã¦è§£èª¬ã—ãŸè¨˜äº‹ï¼
### 72. [Lagrange Multipliers](https://www.youtube.com/watch?v=5-CUqogfPLY)
  - Awesome YouTube video on Lagrange multipliers.
  - ãƒ©ã‚°ãƒ©ãƒ³ã‚¸ãƒ¥ã®æœªå®šä¹—æ•°æ³•ã«ã¤ã„ã¦è§£èª¬ã—ãŸYouTubeå‹•ç”»ï¼
### 73. [Understanding Lagrange Multipliers Visually](https://www.youtube.com/watch?v=5A39Ht9Wcu0)
  - Awesome YouTube video visualizing the concept of Lagrange multipliers.
  - ãƒ©ã‚°ãƒ©ãƒ³ã‚¸ãƒ¥ã®æœªå®šä¹—æ•°æ³•ã«ã¤ã„ã¦è¦–è¦šçš„ã«è§£èª¬ã—ãŸYouTubeå‹•ç”»ï¼
### 74. ğŸ—¾[ãƒ©ã‚°ãƒ©ãƒ³ã‚¸ãƒ¥ã®æœªå®šä¹—æ•°æ³•ã®æ°—æŒã¡ã€æ¡ä»¶ä»˜ãæ¥µå€¤å•é¡Œã€‘](https://www.youtube.com/watch?v=vAwqZmwf4W8)
  - ãƒ¨ãƒ“ãƒãƒªã«ã‚ˆã‚‹ãƒ©ã‚°ãƒ©ãƒ³ã‚¸ãƒ¥ã®æœªå®šä¹—æ•°æ³•ã«ã¤ã„ã¦ã®è§£èª¬å‹•ç”»ï¼å›³å½¢çš„æ„å‘³ã«ã¤ã„ã¦ã®è§£èª¬ã‚’å«ã‚€ï¼
### 75. ğŸ—¾[åˆ¶ç´„ä»˜ãæœ€é©åŒ–å•é¡Œ(KKTæ¡ä»¶/ãƒ©ã‚°ãƒ©ãƒ³ã‚¸ãƒ¥æœªå®šä¹—æ•°æ³•)](https://www.youtube.com/watch?v=bdWTCq98H5c)
  - ãƒ¨ãƒ“ãƒãƒªã«ã‚ˆã‚‹ãƒ©ã‚°ãƒ©ãƒ³ã‚¸ãƒ¥ã®æœªå®šä¹—æ•°æ³•ã«ã¤ã„ã¦ã®è§£èª¬å‹•ç”»ï¼KKTæ¡ä»¶ï¼ˆä¸ç­‰å¼åˆ¶ç´„ã®å ´åˆã®è§£æ³•ï¼‰ã«ã¤ã„ã¦ã®è§£èª¬ã‚’å«ã‚€ï¼
### 76. ğŸ—¾[ãƒ©ã‚°ãƒ©ãƒ³ã‚¸ãƒ¥ã®æœªå®šä¹—æ•°æ³•ã¨ã¯ï½æ„å‘³ã¨è¨¼æ˜ï½](https://mathlandscape.com/lagrange-multiplier/)
  - ãƒ©ã‚°ãƒ©ãƒ³ã‚¸ãƒ¥ã®æœªå®šä¹—æ•°æ³•ã®æ„å‘³ï¼Œå®šç†ã¨ãã®è¨¼æ˜ã‚’è§£èª¬ã—ãŸè¨˜äº‹ï¼

## Awesome-Gradient Descent (å‹¾é…é™ä¸‹æ³•)
### 77. ğŸŒŸ[Gradient descent, how neural networks learn | Deep Learning Chapter 2](https://youtu.be/IHZwWFHWa-w?si=zRN94_SPD4hrQUUI)
  - Awesome explanation of gradient descent in deep learning by 3Blue1Brown.
  - 3Blue1Brownã«ã‚ˆã‚‹ï¼Œæ·±å±¤å­¦ç¿’ã«ãŠã‘ã‚‹å‹¾é…é™ä¸‹æ³•ã«ã¤ã„ã¦ã®è§£èª¬ï¼
### 78. [Optimization for Deep Learning (Momentum, RMSprop, AdaGrad, Adam)](https://youtu.be/NE88eqLngkg?si=qSmU5hpaeYiUtEZw)
  - Awesome explanation of the various online learning methods used in deep learning.
  - æ·±å±¤å­¦ç¿’ã«ç”¨ã„ã‚‰ã‚Œã‚‹æ§˜ã€…ãªã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’æ‰‹æ³•ã«ã¤ã„ã¦ã®è§£èª¬ï¼
### 79. [Mini Batch Gradient Descent (C2W2L01)](https://www.youtube.com/watch?v=4qJaSmvhxi8)
  - Awesome YouTube video by Andrew Ng explaining mini-batch gradient descent.
  - Andrew Ngã«ã‚ˆã‚‹ï¼ŒãƒŸãƒ‹ãƒãƒƒãƒå‹¾é…é™ä¸‹æ³•ã«ã¤ã„ã¦è§£èª¬ã—ãŸYouTubeå‹•ç”».
### 80. [Understanding Mini-Batch Gradient Descent (C2W2L02)](https://www.youtube.com/watch?v=-_4Zi8fCZO4)
  - The second YouTube video by Andrew Ng explaining mini-batch gradient descent.
  - Andrew Ngã«ã‚ˆã‚‹ï¼ŒãƒŸãƒ‹ãƒãƒƒãƒå‹¾é…é™ä¸‹æ³•ã«ã¤ã„ã¦è§£èª¬ã—ãŸYouTubeå‹•ç”»ã®ï¼’æœ¬ç›®.

# ğŸ“š Resourcesï¼ˆå­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹ï¼‰
## Awesome-slidesï¼ˆã‚¹ãƒ©ã‚¤ãƒ‰ï¼‰
### 81. ğŸŒŸ[Online Convex Optimization and Its Surprising Applications](https://groups.oist.jp/sites/default/files/imce/u129210/mlss/Lecture_slide/MLSS2024_Francesco_Orabona.pdf)
  - Awesome slides from MLSS2024 by Orabona on online convex optimization algorithms such as OGD and OMD, and their applications to other fields. The content is quite mathematical but beneficial.
  - MLSS2024ã«ãŠã‘ã‚‹ï¼ŒOrabonaã«ã‚ˆã‚‹OGDã‚„OMDã¨ã„ã£ãŸã‚ªãƒ³ãƒ©ã‚¤ãƒ³å‡¸æœ€é©åŒ–ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨ãã®ä»–åˆ†é‡ã¸ã®å¿œç”¨ã«ã¤ã„ã¦ã®ã‚¹ãƒ©ã‚¤ãƒ‰ï¼ã‹ãªã‚Šæ•°å­¦çš„ãªå†…å®¹ã ãŒæœ‰ç›Šï¼
### 82. [Online Learning Methods for Big Data Analytics](http://www.mysmu.edu.sg/faculty/chhoi/libol/icdm14tuto/index.html)
  - Awesome tutorial presented at IEEE ICDM2014.
  - IEEE ICDM2014ã§ç™ºè¡¨ã•ã‚ŒãŸãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«è¬›æ¼”ï¼
### 83. [Learning Methods for Online Prediction Problems](https://users.cecs.anu.edu.au/~ssanner/MLSS2010/Bartlett1.pdf)
  - Awesome lecture materials from UC Berkeley covering topics from the expert aggregation problem to online convex optimization, with applications such as portfolio optimization.
  - UC Berkeleyã«ãŠã‘ã‚‹è¬›ç¾©è³‡æ–™ï¼ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆçµ±åˆå•é¡Œã‹ã‚‰ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å‡¸æœ€é©åŒ–ï¼Œå¿œç”¨ã¨ã—ã¦ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ã¾ã§ã‚’æ‰±ã£ã¦ã„ã‚‹ï¼
### 84. [Follow the Leader: Theory and Applications](https://www.cs.ubc.ca/labs/lci/mlrg/slides/2019_summer_3_follow_the_leader.pdf)
  - Slides explaining Follow The Leader (FTL) and its derivative algorithms in online learning, along with their applications.
  - ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã«ãŠã‘ã‚‹Follow The Leader (FTL) ã‚„ãã®æ´¾ç”Ÿã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼Œãã—ã¦ãã‚Œã‚‰ã®å¿œç”¨ã«ã¤ã„ã¦è§£èª¬ã—ãŸã‚¹ãƒ©ã‚¤ãƒ‰ï¼
### 85. ğŸ—¾[å¤šè…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œã®ç†è«–ã¨ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ](https://ibisml.org/archive/ibis2014/ibis2014_bandit.pdf)
  - ç¢ºç‡çš„ï¼ŒãŠã‚ˆã³æ•µå¯¾çš„ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œã«ãŠã‘ã‚‹ï¼Œå ±é…¬æœ€å¤§åŒ–ï¼ˆãƒªã‚°ãƒ¬ãƒƒãƒˆæœ€å°åŒ–ï¼‰ã®ãŸã‚ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’è§£èª¬ã—ãŸã‚¹ãƒ©ã‚¤ãƒ‰ï¼
### 86.ğŸ—¾[ã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬ã®ç†è«–ã¨å¿œç”¨](https://www.lab2.kuis.kyoto-u.ac.jp/keisan-genkai/reports/2005/zentai_1/04-takimoto.pdf)
  - æ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚·ãƒªãƒ¼ã‚ºã€Œã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬ã€ï¼ˆå¾Œè¿°ï¼‰ã®è‘—è€…ã§ã‚‚ã‚ã‚‹ç€§æœ¬è‹±äºŒå…ˆç”Ÿã«ã‚ˆã‚‹ã‚¹ãƒ©ã‚¤ãƒ‰ï¼ã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬ã«ãŠã‘ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆçµ±åˆå•é¡Œã¨ãã®å¿œç”¨ä¾‹ã‚’å–ã‚Šä¸Šã’ã¦ã„ã‚‹ï¼

## Awesome-Textbooksï¼ˆæ›¸ç±ï¼‰
### 87. ğŸŒŸ[Prediction, Learning, and Games](https://www.cambridge.org/core/books/prediction-learning-and-games/A05C9F6ABC752FAB8954C885D0065C8F)
  - The bible on online learning, focusing on regret minimization and game-theoretic approaches to sequential decision-making
  - ãƒªã‚°ãƒ¬ãƒƒãƒˆæœ€å°åŒ–ã‚„ã‚²ãƒ¼ãƒ ç†è«–ã‚’é€šã˜ã¦é€æ¬¡æ„æ€æ±ºå®šå•é¡Œã‚’æ‰±ã†ï¼Œã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã®ãƒã‚¤ãƒ–ãƒ«çš„æ›¸ç±ï¼
### 88. [Introduction to Online Convex Optimization](https://sites.google.com/view/intro-oco/)
  - Awesome book by Hazan that covers a wide range of topics in the theory of online convex optimization.
  - Hazanã«ã‚ˆã‚‹ï¼Œã‚ªãƒ³ãƒ©ã‚¤ãƒ³å‡¸æœ€é©åŒ–ã®ç†è«–ã«é–¢ã™ã‚‹å¤šæ§˜ãªãƒˆãƒ”ãƒƒã‚¯ã‚’ã‚«ãƒãƒ¼ã—ãŸå…¥é–€æ›¸ï¼
### 89. ğŸŒŸğŸ—¾[æ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚·ãƒªãƒ¼ã‚º ã€Œã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬ã€](https://www.kspub.co.jp/book/detail/1529229.html)
  - è‘—åãªæ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚·ãƒªãƒ¼ã‚ºã‚ˆã‚Šï¼Œã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ã¦æ›¸ã‹ã‚ŒãŸä¸€å†Šï¼ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆçµ±åˆå•é¡Œã‚„ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å‡¸æœ€é©åŒ–ãªã©ï¼Œã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬ã®ä¸»è¦ãªå†…å®¹ã‚’ä¸€é€šã‚Šå­¦ã¹ã‚‹ï¼
### 90. ğŸ—¾[æ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚·ãƒªãƒ¼ã‚º ã€Œã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ©Ÿæ¢°å­¦ç¿’ã€](https://www.kspub.co.jp/book/detail/1529038.html)
  - åŒã˜ãæ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚·ãƒªãƒ¼ã‚ºã‚ˆã‚Šï¼Œã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ©Ÿæ¢°å­¦ç¿’ã‚’å–ã‚Šä¸Šã’ãŸä¸€å†Šï¼ˆå‡ºç‰ˆã¯ã€Œã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬ã€ã‚ˆã‚Šã‚‚å‰ï¼‰ï¼ã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬ã‚’å«ã‚€ï¼Œã‚ˆã‚Šåºƒç¯„ãªå†…å®¹ã‚’å­¦ã¹ã‚‹ï¼ã€Œã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬ã€ã‚ˆã‚Šã‚‚å¹³æ˜“ï¼
### 91. ğŸ—¾[æ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚·ãƒªãƒ¼ã‚º ã€Œãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œã®ç†è«–ã¨ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€](https://www.kspub.co.jp/book/detail/1529175.html)
  - åŒã˜ãæ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚·ãƒªãƒ¼ã‚ºã‚ˆã‚Šï¼ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œã«ãŠã‘ã‚‹ãƒªã‚°ãƒ¬ãƒƒãƒˆè§£æã‚„å¿œç”¨ä¾‹ãªã©ã‚’ã‚ˆã‚Šå°‚é–€çš„ã«æ‰±ã£ã¦ã„ã‚‹ï¼

## Videosï¼ˆå‹•ç”»ï¼‰
### 92. ğŸŒŸ[An introduction to regret analysis: environment models and best-of-both-worlds](https://youtu.be/pCER8iuTdR4?si=XAL6lP5tj0mMf8yp)
  - Awesome introduction on online learning, regret analysis, and best-of-both-worlds algorithms in the Machine Learning Summer School 2024.
  - ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ï¼Œãƒªã‚°ãƒ¬ãƒƒãƒˆè§£æï¼ŒBest-of-both-worldsã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã¤ã„ã¦ã®Machine Learning Summer School 2024ã§ã®è¬›æ¼”ï¼
### 93. [Predict with online prediction in Vertex AI](https://youtu.be/TEE7uUbXWDY?si=nHXMfZyTb13KpmWD)
  - Awesome tutorial on how to make predictions on tabular datasets with online prediction in Vertex AI. [GitHub Link](https://github.com/rafaello9472/c4ds/tree/main/Predict%20with%20online%20prediction%20in%20Vertex%20AI)
  - Googleã®Vertex AIã‚’ç”¨ã„ã¦è¡¨å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬ã‚’è¡Œã†æ–¹æ³•ã«ã¤ã„ã¦ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ï¼[GitHub Link](https://github.com/rafaello9472/c4ds/tree/main/Predict%20with%20online%20prediction%20in%20Vertex%20AI)
### 94. ["Online" prediction vs "batch" prediction in machine learning](https://youtu.be/DnmWTIeQ7PM?si=Mg8xcbWXyzlP3vLY)
  - Awesome explanation by Chip Huyen on the difference between online prediction and more common batch prediction and their applications.
  - Chip Huyenã«ã‚ˆã‚‹ï¼Œã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬ã¨é¦´æŸ“ã¿æ·±ã„ãƒãƒƒãƒäºˆæ¸¬ã¨ã®é•ã„ã‚„ãã‚Œã‚‰ã®å¿œç”¨ä¾‹ã«ã¤ã„ã¦ã®çŸ­ã„è§£èª¬ï¼
### 95. [ML Drift: Identifying Issues Before You Have a Problem](https://youtu.be/uOG685WFO00?si=7_ti70FDTD-B5tbO)
  - Awesome presentation by Amy Hodler on ML drifts and how to fix them. [Blog](https://www.fiddler.ai/blog/drift-in-machine-learning-how-to-identify-issues-before-you-have-a-problem)
  - Amy Hodlerã«ã‚ˆã‚‹ï¼ŒMLãƒ‰ãƒªãƒ•ãƒˆã‚„ãã®è§£æ±ºæ–¹æ³•ã«ã¤ã„ã¦ã®ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼[ãƒ–ãƒ­ã‚°](https://www.fiddler.ai/blog/drift-in-machine-learning-how-to-identify-issues-before-you-have-a-problem)

## Articlesï¼ˆè¨˜äº‹ï¼‰
### 96. [What is Online Machine Learning?](https://medium.com/value-stream-design/online-machine-learning-515556ff72c5)
  - A blog post explaining the concept of online machine learning.
  - ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã®ã‚³ãƒ³ã‚»ãƒ—ãƒˆã«ã¤ã„ã¦è§£èª¬ã—ãŸãƒ–ãƒ­ã‚°è¨˜äº‹ï¼
### 97. [Anomalies detection using River](https://medium.com/spikelab/anomalies-detection-using-river-398544d3536)
  - A blog post explaining anomaly detection using River, including practical code examples.
  - Riverã‚’ç”¨ã„ãŸç•°å¸¸æ¤œçŸ¥ã«ã¤ã„ã¦ï¼Œå®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰ã‚’äº¤ãˆã¦è§£èª¬ã—ãŸãƒ–ãƒ­ã‚°è¨˜äº‹ï¼
### 98. ğŸŒŸğŸ—¾[ç§ã®ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã€Œã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã€](https://www.ai-gakkai.or.jp/resource/my-bookmark/my-bookmark_vol30-no5/)
  - äººå·¥çŸ¥èƒ½å­¦ä¼šèªŒã®é€£è¼‰ã€Œç§ã®ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã€ã§ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã‚’ç‰¹é›†ã—ãŸéš›ã®è¨˜äº‹ï¼ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã«é–¢ã™ã‚‹ã‚µãƒ¼ãƒ™ã‚¤ã‚„ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ï¼Œé–¢é€£å­¦ä¼šï¼Œé–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã¾ã¨ã‚ã¦ã„ã‚‹ï¼
### 99. ğŸ—¾[ç§ã®ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã€Œå¤šè…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œã€](https://www.ai-gakkai.or.jp/resource/my-bookmark/my-bookmark_vol31-no5/)
  - åŒã˜ãã€Œç§ã®ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã€ã‚ˆã‚Šï¼Œå¤šè…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œã‚’ç‰¹é›†ã—ãŸå›ã®è¨˜äº‹ï¼é€æ¬¡çš„ãªæ„æ€æ±ºå®šã§ã‚ã‚‹ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œã«é–¢ã™ã‚‹ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚„é–¢é€£å­¦ä¼šï¼Œé–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼Œé‡è¦è«–æ–‡ã‚’ã¾ã¨ã‚ã¦ã„ã‚‹ï¼
### 100. [Deus Ex Machinaã€ŒOnline learning and online predictionï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã¨ã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬ã«ã¤ã„ã¦ï¼‰ã€](https://deus-ex-machina-ism.com/?p=17082)
  - Good for understanding the confusing differences between online learning and online prediction, and for gaining an overview of their respective scopes.
  - æ··åŒã—ã‚„ã™ã„ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã¨ã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬ã®é•ã„ã‚’çŸ¥ã‚Šï¼Œãã‚Œãã‚Œã®ç¯„å›²ã‚’æ¦‚è¦³ã™ã‚‹ã®ã«è‰¯ã„ï¼
### 101. [Deus Ex Machinaã€ŒOverview of online forecasting technology and various applications and implementationsï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬æŠ€è¡“ã®æ¦‚è¦ã¨æ§˜ã€…ãªé©ç”¨äº‹ä¾‹ã¨å®Ÿè£…ä¾‹ï¼‰ã€](https://deus-ex-machina-ism.com/?p=53594)
  - It introduces algorithms, libraries, applications, and suitable books for learning used in online prediction.
  - ã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬ã§ä½¿ç”¨ã•ã‚Œã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼Œãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼Œå¿œç”¨ä¾‹ï¼Œå­¦ç¿’ã«é©ã—ãŸæ›¸ç±ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹ï¼
